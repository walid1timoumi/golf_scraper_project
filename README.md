# ğŸŒï¸ Golf Club Price Scraper (GlobalGolf & RockBottomGolf)

This project automatically scrapes golf club listings from two major retailers â€” **GlobalGolf** and **RockBottomGolf** â€” and analyzes the data for trends, brand stats, and best deals. It runs on a fully automated pipeline using **Python + Selenium + GitHub Actions**, with outputs stored in **Google Sheets**, and optional email reporting.

---

## ğŸ“Š Features

- âœ… Real-time scraping from:
  - ğŸ”¹ [globalgolf.com](https://www.globalgolf.com)
  - ğŸ”¹ [rockbottomgolf.com](https://www.rockbottomgolf.com)
- âœ… Handles pagination, popups, and dynamic JS content
- âœ… Extracts: product name, price, brand, URL, and promotional offer
- âœ… Analyzes data: average/min/max prices by brand
- âœ… Outputs to multi-tab Google Sheet
- âœ… Sends summary via email (SendGrid)
- âœ… Fully automated using GitHub Actions (every 3 days)

---

## ğŸ¥ Demo Video

[![Watch the demo](https://img.youtube.com/vi/8FsjIRTiMZM/0.jpg)](https://youtu.be/8FsjIRTiMZM)

> ğŸ“½ï¸ See the full automation pipeline in action â€” scraping golf listings, analyzing them, exporting to Google Sheets, and sending email reports.


---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main.py                    # Main controller
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ globalgolf_scraper.py
â”‚   â””â”€â”€ rockbottom_scraper.py
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ analyzer.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ email_sender.py
â”‚   â””â”€â”€ google_sheets.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ {site}_config.json
â””â”€â”€ .github/workflows/
    â””â”€â”€ run_scraper.yml
```

---

## ğŸ“¦ Sample Data Fields

| Field    | Example                                 |
|----------|-----------------------------------------|
| Name     | TaylorMade SIM2 Max Driver              |
| Price    | $279.99                                 |
| Brand    | TaylorMade                              |
| URL      | https://www.globalgolf.com/product/...  |
| Offer    | Free Shipping / Deal badge              |

---

## ğŸ“ˆ Google Sheets Output

Results are published in a Google Sheet with the following tabs:

- **Raw Data** â€“ complete scraped listings
- **Stats** â€“ avg/min/max price by brand
- **Top Brands** â€“ most frequent brands
- **Best Deals** â€“ lowest price listings
- **Top Expensive** â€“ highest price listings

---

## ğŸš€ Run Locally

```bash
git clone https://github.com/YOUR_USERNAME/golf-scraper.git
cd golf-scraper
pip install -r requirements.txt

# Add credentials and environment values
cp .env.example .env

# Run
python main.py
```

---

## âš™ï¸ GitHub Automation

This project runs automatically on GitHub Actions:

- Scrapes fresh listings every 3 days
- Pushes data to Google Sheets
- Sends summary email

To trigger manually, use the "Run workflow" button on GitHub.

---

## âœ‰ï¸ Email Reporting

Configure via GitHub secrets:
- `SENDGRID_API_KEY`
- `FROM_EMAIL`
- `TO_EMAIL`

---

## ğŸ’¡ Tech Stack

- Python, Selenium, BeautifulSoup
- gspread (Google Sheets API)
- Pandas for analysis
- GitHub Actions (CI/CD)
- SendGrid (email notifications)

---

## ğŸ‘¤ Author

### Walid Timoumi  
Sourcing Specialist & Automation Developer  

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?logo=linkedin)](https://linkedin.com/in/your-link)  
[![Upwork](https://img.shields.io/badge/Upwork-Freelancer-success?logo=upwork)](https://www.upwork.com/freelancers/your-link)

---

> ğŸ¤– Built with â¤ï¸ by Walid â€” Automated, analyzed, and production-ready.
